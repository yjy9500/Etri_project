{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1d9k751RwmjqCnuHU27PY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yjy9500/Etri_project/blob/master/Final_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_1tV_U7Xn3U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "outputId": "deac5743-4199-473d-8526-6bfb670028e7"
      },
      "source": [
        "!pip install tensorflow==1.14\n",
        "#tensorflow 1.14 version 설치"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 91kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.31.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 49.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (49.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.0)\n",
            "Installing collected packages: keras-applications, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgZNlYCEfGHj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "4cb179ff-6a4b-492f-dc9d-d2f3ec2870eb"
      },
      "source": [
        "!pip uninstall scipy\n",
        "!pip install scipy==1.1.0\n",
        "#scipy version 하향 및 1.1.0version 설치"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling scipy-1.4.1:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/scipy-1.4.1.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/scipy/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled scipy-1.4.1\n",
            "Collecting scipy==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 148kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.18.5)\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "Successfully installed scipy-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b43-SPMvtyrn"
      },
      "source": [
        "!pip install module\n",
        "#module 라이브러리 설치"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzVR2elZXpnh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "b9e1ef09-41b6-404b-9955-f3d770ec9f0f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#google drive 사용 허가 및 승인"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4941oXYXemb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7689e673-7bff-4dfd-848a-b15fdc6de5f4"
      },
      "source": [
        "import os \n",
        "os.chdir('/content/gdrive/My Drive')\n",
        "#본인의 드라이브 사용시 /My Drive 의 내용을 본인의 폴더 directory로 변경 가능\n",
        "!pwd\n",
        "#pwd 명령어를 통해 현재 디렉토리의 절대경로를 확인 가능"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMLzKnbMXiNq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "99a50662-1bf0-4f1a-d1a9-8c45340700d5"
      },
      "source": [
        "from __future__ import division\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "import math\n",
        "import numpy as np\n",
        "import pprint\n",
        "import scipy.misc\n",
        "import copy\n",
        "#라이브러리 Import 하는 명령어"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu9nXE-HYMaX"
      },
      "source": [
        "#판별기 함수 생성\n",
        "def discriminator(image, options, reuse=False, name=\"discriminator\"):\n",
        "\n",
        "    with tf.variable_scope(name):\n",
        "        # image is 256 x 256 x input_c_dim\n",
        "        if reuse:\n",
        "            tf.get_variable_scope().reuse_variables()\n",
        "        else:\n",
        "            assert tf.get_variable_scope().reuse is False\n",
        "\n",
        "        h0 = lrelu(conv2d(image, options.df_dim, name='d_h0_conv'))\n",
        "        # h0 is (128 x 128 x self.df_dim)\n",
        "        h1 = lrelu(instance_norm(conv2d(h0, options.df_dim*2, name='d_h1_conv'), 'd_bn1'))\n",
        "        # h1 is (64 x 64 x self.df_dim*2)\n",
        "        h2 = lrelu(instance_norm(conv2d(h1, options.df_dim*4, name='d_h2_conv'), 'd_bn2'))\n",
        "        # h2 is (32x 32 x self.df_dim*4)\n",
        "        h3 = lrelu(instance_norm(conv2d(h2, options.df_dim*8, s=1, name='d_h3_conv'), 'd_bn3'))\n",
        "        # h3 is (32 x 32 x self.df_dim*8)\n",
        "        h4 = conv2d(h3, 1, s=1, name='d_h3_pred')\n",
        "        # h4 is (32 x 32 x 1)\n",
        "        return h4\n",
        "\n",
        "#생성기 함수 생성\n",
        "def generator_resnet(image, options, reuse=False, name=\"generator\"):\n",
        "\n",
        "    with tf.variable_scope(name):\n",
        "        # image is 256 x 256 x input_c_dim\n",
        "        if reuse:\n",
        "            tf.get_variable_scope().reuse_variables()\n",
        "        else:\n",
        "            assert tf.get_variable_scope().reuse is False\n",
        "\n",
        "        def residule_block(x, dim, ks=3, s=1, name='res'):\n",
        "            p = int((ks - 1) / 2)\n",
        "            y = tf.pad(x, [[0, 0], [p, p], [p, p], [0, 0]], \"REFLECT\")      # padding은 양옆 위아래로 1씩만.\n",
        "\n",
        "            # instance_norm은 nomalization.\n",
        "            y = instance_norm(conv2d(y, dim, ks, s, padding='VALID', name=name+'_c1'), name+'_bn1')\n",
        "            y = tf.pad(tf.nn.relu(y), [[0, 0], [p, p], [p, p], [0, 0]], \"REFLECT\")\n",
        "            y = instance_norm(conv2d(y, dim, ks, s, padding='VALID', name=name+'_c2'), name+'_bn2')\n",
        "            return y + x\n",
        "\n",
        "\n",
        "        c0 = tf.pad(image, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\")     # 위 아래 가로 세로로 패딩 3씩.\n",
        "        c1 = tf.nn.relu(instance_norm(conv2d(c0, options.gf_dim, 7, 1, padding='VALID', name='g_e1_c'), 'g_e1_bn'))\n",
        "        c2 = tf.nn.relu(instance_norm(conv2d(c1, options.gf_dim*2, 3, 2, name='g_e2_c'), 'g_e2_bn'))\n",
        "        c3 = tf.nn.relu(instance_norm(conv2d(c2, options.gf_dim*4, 3, 2, name='g_e3_c'), 'g_e3_bn'))        # 64 *64\n",
        "\n",
        "        # define G network with 9 resnet blocks\n",
        "        # 총 cnn 18층.\n",
        "        r1 = residule_block(c3, options.gf_dim*4, name='g_r1')\n",
        "        r2 = residule_block(r1, options.gf_dim*4, name='g_r2')\n",
        "        r3 = residule_block(r2, options.gf_dim*4, name='g_r3')\n",
        "        r4 = residule_block(r3, options.gf_dim*4, name='g_r4')\n",
        "        r5 = residule_block(r4, options.gf_dim*4, name='g_r5')\n",
        "        r6 = residule_block(r5, options.gf_dim*4, name='g_r6')\n",
        "        r7 = residule_block(r6, options.gf_dim*4, name='g_r7')\n",
        "        r8 = residule_block(r7, options.gf_dim*4, name='g_r8')\n",
        "        r9 = residule_block(r8, options.gf_dim*4, name='g_r9')\n",
        "\n",
        "        d1 = deconv2d(r9, options.gf_dim*2, 3, 2, name='g_d1_dc')\n",
        "        d1 = tf.nn.relu(instance_norm(d1, 'g_d1_bn'))\n",
        "        d2 = deconv2d(d1, options.gf_dim, 3, 2, name='g_d2_dc')\n",
        "        d2 = tf.nn.relu(instance_norm(d2, 'g_d2_bn'))\n",
        "        d2 = tf.pad(d2, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\")\n",
        "\n",
        "        # 위에 패딩을 해놨고 7 by 7 필터사용.\n",
        "        pred = tf.nn.tanh(conv2d(d2, options.output_c_dim, 7, 1, padding='VALID', name='g_pred_c'))\n",
        "\n",
        "\n",
        "\n",
        "        return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jffsxqCzYVYC"
      },
      "source": [
        "from scipy.misc import imread, imresize, imsave\n",
        "def abs_criterion(in_, target):\n",
        "    return tf.reduce_mean(tf.abs(in_ - target))\n",
        "\n",
        "def mae_criterion(in_, target):\n",
        "    return tf.reduce_mean((in_-target)**2)\n",
        "\n",
        "def sce_criterion(logits, labels):\n",
        "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))\n",
        "\n",
        "# 이미지를 풀링\n",
        "class ImagePool(object):\n",
        "    def __init__(self, maxsize=50):\n",
        "        self.maxsize = maxsize\n",
        "        self.num_img = 0\n",
        "        self.images = []\n",
        "\n",
        "    def __call__(self, image):\n",
        "        if self.maxsize <= 0:\n",
        "            return image\n",
        "        if self.num_img < self.maxsize:\n",
        "            self.images.append(image)\n",
        "            self.num_img += 1\n",
        "            return image\n",
        "        if np.random.rand() > 0.5:\n",
        "            idx = int(np.random.rand()*self.maxsize)\n",
        "            tmp1 = copy.copy(self.images[idx])[0]\n",
        "            self.images[idx][0] = image[0]\n",
        "            idx = int(np.random.rand()*self.maxsize)\n",
        "            tmp2 = copy.copy(self.images[idx])[1]\n",
        "            self.images[idx][1] = image[1]\n",
        "            return [tmp1, tmp2]\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "\"\"\"=========== 모델 만들 때 필요한 함수 ==============\"\"\"\n",
        "\n",
        "def instance_norm(input, name=\"instance_norm\"):\n",
        "    with tf.variable_scope(name):\n",
        "        depth = input.get_shape()[3]            # 채널 수.\n",
        "\n",
        "        # 평균 1, 표준편차 0.02 nomal distribution, 즉 채널 수 갯수만큼 변수 생성.\n",
        "        scale = tf.get_variable(\"scale\", [depth], initializer=tf.random_normal_initializer(1.0, 0.02, dtype=tf.float32))\n",
        "\n",
        "        #채널 수 갯수 만큼 변수 생성.\n",
        "        offset = tf.get_variable(\"offset\", [depth], initializer=tf.constant_initializer(0.0))\n",
        "\n",
        "        mean, variance = tf.nn.moments(input, axes=[1,2], keep_dims=True)       # 가로, 세로에 대해서 평균과 분산을 구하기.\n",
        "        epsilon = 1e-5\n",
        "        inv = tf.rsqrt(variance + epsilon)\n",
        "        normalized = (input-mean)*inv\n",
        "        return scale*normalized + offset\n",
        "#convolution 함수\n",
        "def conv2d(input_, output_dim, ks=4, s=2, stddev=0.02, padding='SAME', name=\"conv2d\"):\n",
        "    with tf.variable_scope(name):       # 앞에 conv2d가 붙음.\n",
        "        # output_dim == 필터수. ks == 커널 사이즈.(4 x4) s==스트라이드, 활성 함수 없음.\n",
        "        # 이미지 사이즈 가로 세로 각각 0.5배\n",
        "        return slim.conv2d(input_, output_dim, ks, s, padding=padding, activation_fn=None,\n",
        "                            weights_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
        "                            biases_initializer=None)\n",
        "#deconvolution 함수\n",
        "def deconv2d(input_, output_dim, ks=4, s=2, stddev=0.02, name=\"deconv2d\"):\n",
        "    with tf.variable_scope(name):\n",
        "        # 이미지 사이즈 가로 세로 각각 2배됨.\n",
        "        return slim.conv2d_transpose(input_, output_dim, ks, s, padding='SAME', activation_fn=None,\n",
        "                                    weights_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
        "                                    biases_initializer=None)\n",
        "\n",
        "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
        "    return tf.maximum(x, leak*x)\n",
        "\n",
        "\"\"\"======================== 여기는 모델외 모듈들 .==================================\"\"\"\n",
        "\n",
        "_imread = scipy.misc.imread\n",
        "\n",
        "def load_test_data(image_path, fine_size=256):\n",
        "    img = imread(image_path)\n",
        "    img = scipy.misc.imresize(img, [fine_size, fine_size])\n",
        "    img = img/127.5 - 1         # -1에서 1사이로 맞추려고.\n",
        "    return img\n",
        "\n",
        "def load_train_data(image_path, load_size=286, fine_size=256, is_testing=False):\n",
        "    img_A = imread(image_path[0])\n",
        "    img_B = imread(image_path[1])\n",
        "\n",
        "    if not is_testing:  # 훈련 중\n",
        "        img_A = scipy.misc.imresize(img_A, [load_size, load_size])\n",
        "        img_B = scipy.misc.imresize(img_B, [load_size, load_size])\n",
        "        h1 = int(np.ceil(np.random.uniform(1e-2, load_size-fine_size))) # 1에서 load_size-fine_size 사이의 값 하나.\n",
        "        w1 = int(np.ceil(np.random.uniform(1e-2, load_size-fine_size)))\n",
        "        img_A = img_A[h1:h1+fine_size, w1:w1+fine_size]         # 이미지를 랜덤하게 컷팅... why??\n",
        "        img_B = img_B[h1:h1+fine_size, w1:w1+fine_size]\n",
        "\n",
        "        if np.random.random() > 0.5:                # 50프로 확률로 이미지 뒤집기\n",
        "            img_A = np.fliplr(img_A)\n",
        "            img_B = np.fliplr(img_B)\n",
        "\n",
        "    else:   # 테스트 중!\n",
        "        img_A = scipy.misc.imresize(img_A, [fine_size, fine_size])\n",
        "        img_B = scipy.misc.imresize(img_B, [fine_size, fine_size])\n",
        "\n",
        "    img_A = img_A/127.5 - 1.\n",
        "    img_B = img_B/127.5 - 1.\n",
        "\n",
        "    img_AB = np.concatenate((img_A, img_B), axis=2)\n",
        "    # img_AB shape: (fine_size, fine_size, input_c_dim + output_c_dim)\n",
        "    return img_AB\n",
        "\n",
        "def get_image(image_path, image_size, is_crop=True, resize_w=64, is_grayscale = False):\n",
        "    return transform(imread(image_path, is_grayscale), image_size, is_crop, resize_w)\n",
        "\n",
        "def save_images(images, size, image_path):\n",
        "    return imsave(inverse_transform(images), size, image_path)\n",
        "\n",
        "def imread(path, is_grayscale = False):\n",
        "    if (is_grayscale):\n",
        "        return _imread(path, flatten=True).astype(np.float)\n",
        "    else:\n",
        "        return _imread(path, mode='RGB').astype(np.float)\n",
        "\n",
        "def merge_images(images, size):\n",
        "    return inverse_transform(images)\n",
        "\n",
        "def merge(images, size):\n",
        "    h, w = images.shape[1], images.shape[2]\n",
        "    img = np.zeros((h * size[0], w * size[1], 3))\n",
        "    for idx, image in enumerate(images):\n",
        "        i = idx % size[1]\n",
        "        j = idx // size[1]\n",
        "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
        "\n",
        "    return img\n",
        "\n",
        "def imsave(images, size, path):\n",
        "    return scipy.misc.imsave(path, merge(images, size))\n",
        "\n",
        "\n",
        "def center_crop(x, crop_h, crop_w,\n",
        "                resize_h=64, resize_w=64):\n",
        "  if crop_w is None:\n",
        "    crop_w = crop_h\n",
        "  h, w = x.shape[:2]\n",
        "  j = int(round((h - crop_h)/2.))\n",
        "  i = int(round((w - crop_w)/2.))\n",
        "  return scipy.misc.imresize(\n",
        "      x[j:j+crop_h, i:i+crop_w], [resize_h, resize_w])\n",
        "\n",
        "def transform(image, npx=64, is_crop=True, resize_w=64):\n",
        "\n",
        "    if is_crop:\n",
        "        cropped_image = center_crop(image, npx, resize_w=resize_w)\n",
        "    else:\n",
        "        cropped_image = image\n",
        "    return np.array(cropped_image)/127.5 - 1.\n",
        "\n",
        "def inverse_transform(images):\n",
        "    return (images+1.)/2."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyNXtFiKZV1C"
      },
      "source": [
        "from __future__ import division\n",
        "import os\n",
        "import time\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "import module\n",
        "from module import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFVDGaiRER_I"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43IndxabiGXB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a8156d2-db63-479a-b018-b8224068538d"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKnEmEi6ZMRr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "27baa5cd-3303-48f9-8ada-12753e99bf87"
      },
      "source": [
        "from __future__ import division\n",
        "import os\n",
        "import time\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "\n",
        "from module import *\n",
        "#Cyclegan 정의\n",
        "class cyclegan():\n",
        "    def __init__(self, sess, checkpoint_dir, test_dir, dataset_dir, which_direction):\n",
        "        self.sess = sess\n",
        "        self.batch_size = 1           # 배치 사이즈\n",
        "        self.image_size = 256            # 잘리는 사이즈\n",
        "        self.input_c_dim = 3            # 인풋 이미지 채널\n",
        "        self.output_c_dim = 3          # 아웃풋 이미지 채널\n",
        "        self.L1_lambda = 10.0\n",
        "        self.fine_size = 256\n",
        "        self.ngf = 64         # G의 첫번째 conv 레이어 필터수\n",
        "        self.ndf = 64         # F의 첫번째 conv 레이어 필터수\n",
        "        self.output_nc = 3\n",
        "        self.max_size = 50\n",
        "        self.beta1 = 0.5        # adam 두번째 옵션\n",
        "        self.epoch = 200        # 200에폭 돌려라.\n",
        "        self.epoch_step = 100   # lr를 줄이는 스탭\n",
        "        self.train_size = 1e8   # 훈련시 이미지 갯수??\n",
        "        self.lr_init = 0.0002        # 최초의 lr\n",
        "        self.load_size = 286\n",
        "        self.save_freq = 500    # 저장 빈도\n",
        "        self.continue_train = True         # 항상 연속해서 훈련.\n",
        "\n",
        "        # 경로 모음\n",
        "        self.checkpoint_dir = checkpoint_dir                # checkpoint 경로.\n",
        "        self.dataset_dir = dataset_dir              # dataset 경로\n",
        "        self.test_dir = test_dir                    # 테스트한 이미지를 저장하는 경로.\n",
        "\n",
        "        # G와 D\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator_resnet  # resnet을 사용한 generator\n",
        "\n",
        "        # loss_fn\n",
        "        self.original_GAN_loss = mae_criterion\n",
        "\n",
        "        self.which_direction = which_direction\n",
        "\n",
        "        OPTIONS = namedtuple('OPTIONS', 'batch_size image_size \\\n",
        "                                      gf_dim df_dim output_c_dim')\n",
        "        self.options = OPTIONS._make((self.batch_size, self.fine_size,\n",
        "                                      self.ngf, self.ndf, self.output_nc,))       #ngf 는 제너레이터 함수의 첫번째 conv레이어 필터수\n",
        "                                      #self.phase == 'train'))\n",
        "\n",
        "        self._build_model()         # 모델 생성.\n",
        "        #writer = tf.train.SummaryWriter(\"/tmp/test_logs\", sess.graph)\n",
        "        self.saver = tf.train.Saver()\n",
        "        self.pool = ImagePool(self.max_size)\n",
        "\n",
        "    def _build_model(self):\n",
        "        self.real_data = tf.placeholder(tf.float32,\n",
        "                                        [None, self.image_size, self.image_size,\n",
        "                                         self.input_c_dim + self.output_c_dim],     # input 이미지 채널과 output 이미지 채널 수  # 아마 둘다 3. RGB라서.\n",
        "                                        name='real_A_and_B_images')\n",
        "\n",
        "        self.real_A = self.real_data[:, :, :, :self.input_c_dim]            # self.real_data의 앞부분, 즉 real A\n",
        "        self.real_B = self.real_data[:, :, :, self.input_c_dim:self.input_c_dim + self.output_c_dim] # real B\n",
        "        self.fake_B = self.generator(self.real_A, self.options, False, name=\"generatorA2B\")     # A를 가짜 B로 바꾸기.\n",
        "        self.fake_A_ = self.generator(self.fake_B, self.options, False, name=\"generatorB2A\")    # 가짜 B를 가짜 A로 바꾸기\n",
        "\n",
        "        # 앞에 이미 정의한 거라서 reuse를 사용함.\n",
        "        self.fake_A = self.generator(self.real_B, self.options, True, name=\"generatorB2A\")      # 진짜 B를 가짜 A로 바꾸기\n",
        "        self.fake_B_ = self.generator(self.fake_A, self.options, True, name=\"generatorA2B\")     # 가짜 A를 가짜 B로 바꾸기\n",
        "        self.DB_fake = self.discriminator(self.fake_B, self.options, reuse=False, name=\"discriminatorB\")        # 32 BY 32 가 나와..\n",
        "        self.DA_fake = self.discriminator(self.fake_A, self.options, reuse=False, name=\"discriminatorA\")\n",
        "\n",
        "        \"\"\"  G & F 를 학습 시키키 위해 필요한 최종 loss  \"\"\"\n",
        "        self.g_loss = self.original_GAN_loss(self.DA_fake, tf.ones_like(self.DA_fake)) \\\n",
        "            + self.original_GAN_loss(self.DB_fake, tf.ones_like(self.DB_fake)) \\\n",
        "            + self.L1_lambda * abs_criterion(self.real_A, self.fake_A_) \\\n",
        "            + self.L1_lambda * abs_criterion(self.real_B, self.fake_B_)\n",
        "\n",
        "        \"\"\"    신규 추가 loss   \n",
        "        #########################################################\n",
        "        self.A_and_GA_hyunbo = self.generator(self.real_A, self.options, True, name=\"generatorB2A\")\n",
        "        self.B_and_GB_hyunbo = self.generator(self.real_B, self.options, True, name=\"generatorA2B\")\n",
        "        self.g_loss_by_hyunbo = self.L1_lambda * abs_criterion(self.real_A, self.A_and_GA_hyunbo) \\\n",
        "                                    + self.L1_lambda * abs_criterion(self.real_B, self.B_and_GB_hyunbo)\n",
        "        #########################################################\"\"\"\n",
        "        \"\"\" =============================== 여기부터는 D의 학습입니다. ==========================\"\"\"\n",
        "        # 대문자 D를 함수 처럼 작용하는 듯.\n",
        "        self.fake_A_sample = tf.placeholder(tf.float32,\n",
        "                                            [None, self.image_size, self.image_size,\n",
        "                                             self.input_c_dim], name='fake_A_sample')\n",
        "        self.fake_B_sample = tf.placeholder(tf.float32,\n",
        "                                            [None, self.image_size, self.image_size,\n",
        "                                             self.output_c_dim], name='fake_B_sample')\n",
        "\n",
        "        # 진짜 B를 넣어서 32 by 32 를 나오게 함.\n",
        "        self.DB_real = self.discriminator(self.real_B, self.options, reuse=True, name=\"discriminatorB\")\n",
        "        # 진짜 A를 넣어서 32 by 32 를 나오게 함.\n",
        "        self.DA_real = self.discriminator(self.real_A, self.options, reuse=True, name=\"discriminatorA\")\n",
        "        # 가짜 B를 넣어서 32 by 32 를 나오게 함.\n",
        "        self.DB_fake_sample = self.discriminator(self.fake_B_sample, self.options, reuse=True, name=\"discriminatorB\")\n",
        "        # 가짜 A를 넣어서 32 by 32 를 나오게 함.\n",
        "        self.DA_fake_sample = self.discriminator(self.fake_A_sample, self.options, reuse=True, name=\"discriminatorA\")\n",
        "\n",
        "        \"\"\" 진짜 B와 가짜 B를 구별하는 D_loss\"\"\"\n",
        "        self.db_loss_real = self.original_GAN_loss(self.DB_real, tf.ones_like(self.DB_real))\n",
        "        self.db_loss_fake = self.original_GAN_loss(self.DB_fake_sample, tf.zeros_like(self.DB_fake_sample))\n",
        "        self.db_loss = (self.db_loss_real + self.db_loss_fake) / 2\n",
        "\n",
        "        \"\"\" 진짜 A와 가짜 A를 구별하는 D_loss \"\"\"\n",
        "        self.da_loss_real = self.original_GAN_loss(self.DA_real, tf.ones_like(self.DA_real))\n",
        "        self.da_loss_fake = self.original_GAN_loss(self.DA_fake_sample, tf.zeros_like(self.DA_fake_sample))\n",
        "        self.da_loss = (self.da_loss_real + self.da_loss_fake) / 2\n",
        "\n",
        "        \"\"\" D를 학습시키기 위한 최종 loss \"\"\"\n",
        "        self.d_loss = self.da_loss + self.db_loss\n",
        "\n",
        "        \"\"\"============================================================================================\"\"\"\n",
        "\n",
        "        \"\"\" test를 위해 만든 곳 \"\"\"\n",
        "        self.test_A = tf.placeholder(tf.float32,\n",
        "                                     [None, self.image_size, self.image_size,\n",
        "                                      self.input_c_dim], name='test_A')\n",
        "        self.test_B = tf.placeholder(tf.float32,\n",
        "                                     [None, self.image_size, self.image_size,\n",
        "                                      self.output_c_dim], name='test_B')\n",
        "        self.testB = self.generator(self.test_A, self.options, True, name=\"generatorA2B\")\n",
        "        self.testA = self.generator(self.test_B, self.options, True, name=\"generatorB2A\")\n",
        "\n",
        "\n",
        "        \"\"\" D를 학습시킬 때의 변수와 G를 학습시킬 때의 변수를 나눠놓음. \"\"\"\n",
        "        t_vars = tf.trainable_variables()\n",
        "        self.d_vars = [var for var in t_vars if 'discriminator' in var.name]\n",
        "        self.g_vars = [var for var in t_vars if 'generator' in var.name]\n",
        "        for var in t_vars: print(var.name)\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Train cyclegan\"\"\"\n",
        "        self.lr_var = tf.placeholder(tf.float32, None, name='learning_rate')\n",
        "        self.d_optim = tf.train.AdamOptimizer(self.lr_var, beta1=self.beta1) \\\n",
        "            .minimize(self.d_loss, var_list=self.d_vars)\n",
        "        self.g_optim = tf.train.AdamOptimizer(self.lr_var, beta1=self.beta1) \\\n",
        "            .minimize(self.g_loss, var_list=self.g_vars)\n",
        "\n",
        "        \"\"\"\n",
        "        #########################################################\n",
        "        self.hyunbo_optim = tf.train.AdamOptimizer(self.lr_var, beta1=self.beta1) \\\n",
        "            .minimize(self.g_loss_by_hyunbo, var_list=self.g_vars)\n",
        "        #########################################################\n",
        "        \"\"\"\n",
        "\n",
        "        init_op = tf.global_variables_initializer()     #모든 변수 초기화.\n",
        "        self.sess.run(init_op)\n",
        "\n",
        "        counter = 1\n",
        "        start_time = time.time()\n",
        "\n",
        "        if self.continue_train:\n",
        "            suc_or_fal, num_of_train = self.load()          # 성공, 실패 유무 와 훈련횟수\n",
        "            if suc_or_fal:\n",
        "                print(\" check point 가져오기 성공\")\n",
        "                counter = int(num_of_train.split('-')[1])                     # 이어서 저장하기 위해서..\n",
        "            else:\n",
        "                print(\" check point 가져오기 실패\")\n",
        "\n",
        "        for epoch in range(self.epoch):\n",
        "            dataA = glob('{}/*.*'.format(self.dataset_dir + '/trainA'))\n",
        "            dataB = glob('{}/*.*'.format(self.dataset_dir + '/trainB'))\n",
        "            print(\"num of dataA : \", dataA.__len__())\n",
        "            np.random.shuffle(dataA)\n",
        "            np.random.shuffle(dataB)\n",
        "            batch_idxs = min(min(len(dataA), len(dataB)), self.train_size) // self.batch_size\n",
        "            lr = self.lr_init if epoch < self.epoch_step else self.lr_init*(self.epoch-epoch)/(self.epoch-self.epoch_step)    # lr이 작아짐. 100에폭이 지나면.\n",
        "\n",
        "            for idx in range(0, batch_idxs):\n",
        "                batch_files = list(zip(dataA[idx * self.batch_size:(idx + 1) * self.batch_size],\n",
        "                                       dataB[idx * self.batch_size:(idx + 1) * self.batch_size]))\n",
        "                batch_images = [load_train_data(batch_file, self.load_size, self.fine_size) for batch_file in batch_files]      # 이미지 크기 바꾸기.\n",
        "                batch_images = np.array(batch_images).astype(np.float32)\n",
        "\n",
        "                # Update G network and record fake outputs\n",
        "                fake_A, fake_B, _ = self.sess.run(\n",
        "                    [self.fake_A, self.fake_B, self.g_optim],\n",
        "                    feed_dict={self.real_data: batch_images, self.lr_var: lr})\n",
        "\n",
        "                #self.writer.add_summary(summary_str, counter)\n",
        "                #[fake_A, fake_B] = self.pool([fake_A, fake_B])\n",
        "\n",
        "                # Update D network\n",
        "                self.sess.run( [self.d_optim],\n",
        "                               feed_dict={self.real_data: batch_images,\n",
        "                                    self.fake_A_sample: fake_A,\n",
        "                                    self.fake_B_sample: fake_B,\n",
        "                                    self.lr_var: lr})\n",
        "                #self.writer.add_summary(summary_str, counter)\n",
        "\n",
        "                counter += 1\n",
        "                print((\"Epoch: [%2d] [%4d/%4d] time: %4.4f\" % (\n",
        "                    epoch, idx, batch_idxs, time.time() - start_time)))\n",
        "\n",
        "                # 저장.\n",
        "                if np.mod(counter, self.save_freq) == 2:\n",
        "                    self.save(counter)\n",
        "                    print(\"ckpt 저장 완료\")\n",
        "\n",
        "    def save(self, step):\n",
        "\n",
        "        step_str = str(step)\n",
        "\n",
        "        self.saver.save(self.sess,\n",
        "                        self.checkpoint_dir + \"/\" + step_str,\n",
        "                        global_step=step)\n",
        "\n",
        "        \"\"\" 여기는 ckpt 파일을 gdrive에 올리는 코드입니다.\"\"\"\n",
        "        \"\"\"latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "        file_name = latest.split(\"/\")\n",
        "        file_name = file_name[-1]\n",
        "        list = ['.data-00000-of-00001', '.index', '.meta']\n",
        "        for x in list:\n",
        "            drive_service = build('drive', 'v3')\n",
        "            file_metadata = {\n",
        "                'name': file_name + x,  # 구글에 올라가는 이름\n",
        "                'mimeType': None\n",
        "            }\n",
        "            media = MediaFileUpload('' + latest + x,\n",
        "                                    mimetype=None,\n",
        "                                    resumable=True)\n",
        "            created = drive_service.files().create(body=file_metadata,\n",
        "                                                   media_body=media,\n",
        "                                                   fields='id').execute()\n",
        "            print('File ID: {}'.format(created.get('id')))\n",
        "            print(x + \"gdrive에 올리기 성공\")\"\"\"\n",
        "\n",
        "    def load(self):\n",
        "        print(\" [*] Reading checkpoint...\")\n",
        "\n",
        "        #model_dir = \"%s_%s\" % (self.dataset_dir, self.image_size)\n",
        "        #checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
        "\n",
        "        ckpt = tf.train.get_checkpoint_state(self.checkpoint_dir)\n",
        "        if ckpt and ckpt.model_checkpoint_path:\n",
        "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
        "            self.saver.restore(self.sess, os.path.join(self.checkpoint_dir, ckpt_name))\n",
        "            print(\" 체크 포인트 이름!! : \", ckpt_name)\n",
        "            index = ckpt_name.find(\"-\")\n",
        "            num_of_train = ckpt_name[index + 1:]\n",
        "            print(\" 불러온 ckpt 횟수 : \", num_of_train)\n",
        "            time.sleep(10)\n",
        "            return True, num_of_train\n",
        "        else:\n",
        "            print(\"check point가 경로에 없습니다.\")\n",
        "            return False, 1             # 리턴값 맞춰주기 위해 씀. 아무값이나 리턴\n",
        "\n",
        "    def test(self):\n",
        "        \"\"\"Test cyclegan\"\"\"\n",
        "        init_op = tf.global_variables_initializer()\n",
        "        self.sess.run(init_op)\n",
        "        if self.which_direction == 'AtoB':\n",
        "            sample_files = glob('{}/*.*'.format(self.dataset_dir + '/testA'))\n",
        "            print(\"dataset 가져오기 성공.\")\n",
        "        elif self.which_direction == 'BtoA':\n",
        "            sample_files = glob('{}/*.*'.format(self.dataset_dir + '/testB'))\n",
        "            print(\"dataset 가져오기 성공.\")\n",
        "        else:\n",
        "            raise Exception('AtoB BtoA 둘중 하나는 선택하세요.')\n",
        "\n",
        "        if self.load():\n",
        "            print(\" check point 가져오기 성공\")\n",
        "        else:\n",
        "            print(\" check point 가져오기 실패\")\n",
        "\n",
        "        if self.which_direction == 'AtoB':\n",
        "            out_var, in_var = (self.testB, self.test_A)\n",
        "        else:\n",
        "            out_var, in_var = (self.testA, self.test_B)\n",
        "\n",
        "        for sample_file in sample_files:\n",
        "            print('Processing image: ' + sample_file)\n",
        "            sample_image = [load_test_data(sample_file, self.fine_size)]\n",
        "            sample_image = np.array(sample_image).astype(np.float32)\n",
        "            image_path = os.path.join(self.test_dir,\n",
        "                                      '{0}_{1}'.format(self.which_direction, os.path.basename(sample_file)))\n",
        "            fake_img = self.sess.run(out_var, feed_dict={in_var: sample_image})\n",
        "            print(\"start saving\")\n",
        "            save_images(fake_img, [1, 1], image_path)\n",
        "\n",
        "\n",
        "def main():\n",
        "    checkpoint_dir = './checkpoint/face_256'             # 체크포인트 경로\n",
        "    test_dir = './test'                          # 테스트 이미지가 저장되는 경로\n",
        "    dataset_dir = './datasets'                         # 데이터셋 위치    trainA trainB testA testB\n",
        "    phase = \"test\"  # or test\n",
        "    which_direction = \"BtoA\"        # or BtoA .  테스트시 변환 방향\n",
        "    # 이미지 저장은 test 경로를 따로 만들어서 함.\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "    if not os.path.exists(test_dir):\n",
        "        os.makedirs(test_dir)\n",
        "\n",
        "    tfconfig = tf.ConfigProto(allow_soft_placement=True)        # gpu를 사용하겠습니다.\n",
        "    tfconfig.gpu_options.allow_growth = True\n",
        "\n",
        "    with tf.Session(config=tfconfig) as sess:\n",
        "        model = cyclegan(sess, checkpoint_dir = checkpoint_dir, test_dir = test_dir,\\\n",
        "                         dataset_dir= dataset_dir, which_direction= which_direction)\n",
        "        if phase == 'train':\n",
        "            print(\" 훈련 시작\")\n",
        "            model.train()\n",
        "        elif phase == \"test\":\n",
        "            print(\" 테스트 시작\")\n",
        "            model.test()\n",
        "        else:\n",
        "            print(\" train??? test???? 둘중하나는 고르세요.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-09332b60c61b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-09332b60c61b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcyclegan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m                         \u001b[0mdataset_dir\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich_direction\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mwhich_direction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" 훈련 시작\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-09332b60c61b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess, checkpoint_dir, test_dir, dataset_dir, which_direction)\u001b[0m\n\u001b[1;32m     50\u001b[0m                                       \u001b[0;31m#self.phase == 'train'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# 모델 생성.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;31m#writer = tf.train.SummaryWriter(\"/tmp/test_logs\", sess.graph)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-09332b60c61b>\u001b[0m in \u001b[0;36m_build_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_c_dim\u001b[0m\u001b[0;34m]\u001b[0m            \u001b[0;31m# self.real_data의 앞부분, 즉 real A\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_c_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_c_dim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_c_dim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# real B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"generatorA2B\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# A를 가짜 B로 바꾸기.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_A_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"generatorB2A\"\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# 가짜 B를 가짜 A로 바꾸기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-7a98802da628>\u001b[0m in \u001b[0;36mgenerator_resnet\u001b[0;34m(image, options, reuse, name)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"REFLECT\"\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# 위 아래 가로 세로로 패딩 3씩.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgf_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'VALID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g_e1_c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g_e1_bn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgf_dim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g_e2_c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g_e2_bn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgf_dim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g_e3_c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g_e3_bn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# 64 *64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-60c9fcc50b96>\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input_, output_dim, ks, s, stddev, padding, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         return slim.conv2d(input_, output_dim, ks, s, padding=padding, activation_fn=None,\n\u001b[1;32m     59\u001b[0m                             \u001b[0mweights_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                             biases_initializer=None)\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdeconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"deconv2d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mconvolution2d\u001b[0;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)\u001b[0m\n\u001b[1;32m   1157\u001b[0m       \u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m       \u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m       conv_dims=2)\n\u001b[0m\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope, conv_dims)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0m_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         _reuse=reuse)\n\u001b[0;32m-> 1057\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;31m# Add variables to collections.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m     \"\"\"\n\u001b[0;32m-> 1479\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_subclass_implementers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m           \u001b[0;31m# Wrapping `call` function in autograph to allow for dynamic control\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1879\u001b[0m       \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m     \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m     \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m       self.bias = self.add_weight(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mgetter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    385\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1494\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1237\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m   def _get_partitioned_variable(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    543\u001b[0m           function_utils.has_kwargs(custom_getter)):\n\u001b[1;32m    544\u001b[0m         \u001b[0mcustom_getter_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"constraint\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcustom_getter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m       return _true_getter(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mlayer_variable_getter\u001b[0;34m(getter, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1759\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlayer_variable_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rename'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1761\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_model_variable_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_variable_getter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36m_model_variable_getter\u001b[0;34m(getter, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, rename, use_resource, synchronization, aggregation, **_)\u001b[0m\n\u001b[1;32m   1750\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\u001b[0m in \u001b[0;36mmodel_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m    356\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    512\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     synchronization, aggregation, trainable = (\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"tensorflow/python\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[0;32m--> 864\u001b[0;31m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    865\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Variable generatorA2B/g_e1_c/Conv/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 283, in variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 355, in model_variable\n    aggregation=aggregation)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 182, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1752, in _model_variable_getter\n    aggregation=aggregation)\n"
          ]
        }
      ]
    }
  ]
}